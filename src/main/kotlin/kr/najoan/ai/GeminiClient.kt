package kr.najoan.ai

import com.google.genai.Client
import com.google.genai.types.Content
import com.google.genai.types.GenerateContentConfig
import com.google.genai.types.GoogleSearch
import com.google.genai.types.HarmBlockThreshold
import com.google.genai.types.HarmCategory
import com.google.genai.types.Part
import com.google.genai.types.SafetySetting
import com.google.genai.types.ThinkingConfig
import com.google.genai.types.Tool
import org.slf4j.LoggerFactory

private val logger = LoggerFactory.getLogger("GeminiClient")

object GeminiClient {
    private lateinit var client: Client
    private const val MODEL_NAME = "gemini-2.5-flash"

    fun initialize(apiKey: String) {
        client = Client.builder()
            .apiKey(apiKey)
            .build()
    }

    /**
     * AIì—ê²Œ ë©”ì‹œì§€ë¥¼ ë³´ë‚´ê³  ì‘ë‹µì„ ë°›ìŠµë‹ˆë‹¤.
     * @param userMessage ì‚¬ìš©ì ë©”ì‹œì§€
     * @param systemPrompt ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (AIì˜ ì„±ê²©/í–‰ë™ ì •ì˜)
     * @param conversationContext ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬ (ì„ íƒì‚¬í•­)
     * @return AIì˜ ì‘ë‹µ
     */
    fun generateResponse(
        userMessage: String,
        systemPrompt: String,
        conversationContext: String = ""
    ): String {
        return try {
            val safetySettings = listOf(
                SafetySetting.builder()
                    .category(HarmCategory.Known.HARM_CATEGORY_HARASSMENT)
                    .threshold(HarmBlockThreshold.Known.BLOCK_ONLY_HIGH)
                    .build(),
                SafetySetting.builder()
                    .category(HarmCategory.Known.HARM_CATEGORY_HATE_SPEECH)
                    .threshold(HarmBlockThreshold.Known.BLOCK_ONLY_HIGH)
                    .build(),
                SafetySetting.builder()
                    .category(HarmCategory.Known.HARM_CATEGORY_SEXUALLY_EXPLICIT)
                    .threshold(HarmBlockThreshold.Known.BLOCK_ONLY_HIGH)
                    .build(),
                SafetySetting.builder()
                    .category(HarmCategory.Known.HARM_CATEGORY_DANGEROUS_CONTENT)
                    .threshold(HarmBlockThreshold.Known.BLOCK_ONLY_HIGH)
                    .build()
            )

            val systemInstruction = Content.fromParts(Part.fromText(systemPrompt))

            val googleSearchTool = Tool.builder().googleSearch(GoogleSearch.builder()).build()

            val config =
                GenerateContentConfig.builder()
                    // Sets the thinking budget to 0 to disable thinking mode
                    .thinkingConfig(ThinkingConfig.builder().thinkingBudget(0))
                    .candidateCount(1)
                    .maxOutputTokens(1024)
                    .safetySettings(safetySettings)
                    .systemInstruction(systemInstruction)
                    .tools(googleSearchTool)
                    .build()

            // í”„ë¡¬í”„íŠ¸ êµ¬ì„±: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ + ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ + í˜„ì¬ ë©”ì‹œì§€
            val fullPrompt = buildString {
                if (conversationContext.isNotEmpty()) {
                    append("=== ì´ì „ ëŒ€í™” ===\n")
                    append(conversationContext)
                    append("\n\n=== ìƒˆë¡œìš´ ë©”ì‹œì§€ ===\n")
                }

                append("ì‚¬ìš©ì: $userMessage")
            }

            val response = client.models.generateContent(
                MODEL_NAME,
                fullPrompt,
                config
            )

            response.text() ?: "ì‘ë‹µì„ ë°›ì„ ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤..."

        } catch (e: Exception) {
            logger.error("Gemini API ì˜¤ë¥˜: ${e.message}", e)
            "ì£„ì†¡í•©ë‹ˆë‹¤... ë­”ê°€ ì´ìƒí•œë°ìš”? ğŸ¥º"
        }
    }
}
